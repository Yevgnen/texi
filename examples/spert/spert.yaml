---
# Project
project: "spert"

# Datasets
data_dir: "./data"

# Training
backend: null
nproc_per_node: null
seed: null
save_path: "output/"
max_epochs: 20
lr: 0.00005
lr_warmup: 0.1
weight_decay: 0.01
max_grad_norm: 1.0
schedule_steps: 1

# Dataloader
train_batch_size: 8
eval_batch_size: 4
num_workers: 0
pin_memory: true
non_blocking: true

# Evaluation
eval_train: false
eval_steps: "epoch"
eval_metric: "RE.all.f1"
save_best_models: 1

# Early Stopping
early_stopping: false
patience: 10

# Logging
log_steps: 100
tensorboard: true
wandb: true
debug: false

# Model
pretrained_model: "bert-base-cased"
embedding_dim: 25
dropout: 0.1
global_context_pooling: "cls"
negative_entity_type: "NEGATIVE_ENTITY"
negative_relation_type: "NEGATIVE_RELATION"
num_negative_entities: 100
num_negative_relations: 100
max_entity_length: 10
max_relation_pairs: 1000
relation_filter_threshold: 0.4
token_delimiter: " "
split_delimiter: null
max_length: 150
